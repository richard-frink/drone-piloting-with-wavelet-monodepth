{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDP Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_wavelets import IDWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.decoders import SparseDecoderWave, DecoderWave, Decoder\n",
    "from networks.encoders import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        \n",
    "        decoder_width = 0.5        \n",
    "        self.encoder = DenseEncoder(normalize_input=opts.normalize_input, pretrained=opts.pretrained_encoder)                       \n",
    "        self.decoder = Decoder(enc_features=self.encoder.num_ch_enc, decoder_width=decoder_width)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder( self.encoder(x) )\n",
    "\n",
    "class DenseModel(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super(DenseModel, self).__init__()\n",
    "        \n",
    "        decoder_width = 0.5\n",
    "        self.encoder = DenseEncoder(normalize_input=opts.normalize_input, pretrained=opts.pretrained_encoder)                \n",
    "        self.decoder = DecoderWave(enc_features=self.encoder.num_ch_enc, decoder_width=decoder_width)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder( self.encoder(x) )\n",
    "    \n",
    "    \n",
    "class SparseModel(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super(SparseModel, self).__init__()\n",
    "        \n",
    "        decoder_width = 0.5        \n",
    "        self.encoder = DenseEncoder(normalize_input=opts.normalize_input, pretrained=opts.pretrained_encoder)        \n",
    "        self.decoder = SparseDecoderWave(enc_features=self.encoder.num_ch_enc, decoder_width=decoder_width)\n",
    "\n",
    "    def forward(self, x, thresh_ratio=0.1):\n",
    "        return self.decoder( self.encoder(x), thresh_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options(object):\n",
    "    def __init__(self):\n",
    "        super(Options, self).__init__()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Sparse DenseDepth Decoder\n"
     ]
    }
   ],
   "source": [
    "# Encoder Parameters\n",
    "\n",
    "opts = Options()\n",
    "\n",
    "\n",
    "opts.encoder_type = \"densenet\"\n",
    "opts.output_scales =  [0, 1, 2, 3]  \n",
    "opts.normalize_input = True\n",
    "opts.use_wavelets = True      \n",
    "opts.pretrained_encoder = False\n",
    "\n",
    "models = {}\n",
    "\n",
    "model = DenseModel(opts)\n",
    "sparse_model = SparseModel(opts)\n",
    "baseline_model = BaselineModel(opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load weights, set to eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_load = [\"model\"]\n",
    "\n",
    "def load_model(model, load_weights_folder):\n",
    "    \"\"\"Load model(s) from disk\n",
    "    \"\"\"\n",
    "    load_weights_folder = os.path.expanduser(load_weights_folder)\n",
    "\n",
    "    assert os.path.isdir(load_weights_folder), \\\n",
    "        \"Cannot find folder {}\".format(load_weights_folder)\n",
    "    print(\"loading model from folder {}\".format(load_weights_folder))    \n",
    "\n",
    "    n = \"model\"\n",
    "    print(\"Loading {} weights...\".format(n))\n",
    "    path = os.path.join(load_weights_folder, \"{}.pth\".format(n))\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(path, map_location={\"cuda:0\": \"cpu\"})\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Cannot find folder ./checkpoints/waveletmonodepth_densenet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-384cec545ae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./checkpoints/waveletmonodepth_densenet\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-dbd2e6f6c8d2>\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(model, load_weights_folder)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mload_weights_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_weights_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_weights_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;34m\"Cannot find folder {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_weights_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading model from folder {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_weights_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Cannot find folder ./checkpoints/waveletmonodepth_densenet"
     ]
    }
   ],
   "source": [
    "model_path = \"./checkpoints/waveletmonodepth_densenet\"\n",
    "load_model(model, model_path)\n",
    "model.eval()\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Loading model weights\\t\", end=\"\")\n",
    "load_model(sparse_model, model_path)\n",
    "sparse_model.eval()\n",
    "print(\"Done\")\n",
    "\n",
    "model_path = \"./checkpoints/baseline_densenet\"\n",
    "load_model(baseline_model, model_path)\n",
    "baseline_model.eval()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'data\\nyu_depth_v2_labeled.mat', errno = 2, error message = 'No such file or directory', flags = 40, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-66377dfa3716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mnyu_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mnyu_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnyu_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nyu_depth_v2_labeled.mat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0msplits_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnyu_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nyuv2_splits.mat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"testNdxs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'data\\nyu_depth_v2_labeled.mat', errno = 2, error message = 'No such file or directory', flags = 40, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import scipy.io as io\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from data import ToTensor\n",
    "import numpy as np\n",
    "\n",
    "nyu_root = \"data\"\n",
    "nyu_dataset = h5py.File(os.path.join(nyu_root, \"nyu_depth_v2_labeled.mat\"), 'r', libver='latest', swmr=True)\n",
    "splits_idx = io.loadmat(os.path.join(nyu_root, \"nyuv2_splits.mat\"))[\"testNdxs\"]\n",
    "\n",
    "def idx2nyu(idx):\n",
    "    return int(splits_idx[idx])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nyu_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7900a1806652>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m651\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnyu_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"images\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2nyu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnyu_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"depths\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2nyu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"depth\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nyu_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 651\n",
    "img = nyu_dataset[\"images\"][idx2nyu(idx)].transpose(2,1,0)\n",
    "depth = nyu_dataset[\"depths\"][idx2nyu(idx)].transpose(1,0)\n",
    "\n",
    "sample = {\"image\": Image.fromarray(img), \"depth\": Image.fromarray((depth*255/10000).astype('int32'))}\n",
    "sample = to_tensor(sample)\n",
    "img_tensor = sample[\"image\"].unsqueeze(0)\n",
    "thresh_ratio = 0.04\n",
    "with torch.no_grad():\n",
    "    outputs = model(img_tensor)    \n",
    "    baseline_outputs = baseline_model(img_tensor)\n",
    "    sparse_outputs = sparse_model(img_tensor, -10)\n",
    "    total_ops_dense = sparse_outputs['total_ops']    \n",
    "    sparse_outputs = sparse_model(img_tensor, thresh_ratio)         \n",
    "    \n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(img_tensor[0].permute(1,2,0), cmap=\"plasma\")\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(baseline_outputs[(\"disp\", 0)][0,0], cmap=\"plasma\")\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(outputs[(\"disp\", 0)][0,0], cmap=\"plasma\")\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(sparse_outputs[(\"disp\", 0)][0,0], cmap=\"plasma\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7bc8d57dc916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mthop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclever_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mptflops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_model_complexity_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeature_maps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'thop'"
     ]
    }
   ],
   "source": [
    "from thop import profile, clever_format\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "with torch.no_grad():\n",
    "    feature_maps = baseline_model.encoder(img_tensor)\n",
    "    macs_all, _ = get_model_complexity_info(baseline_model, tuple(img_tensor.shape[1:]),\n",
    "                                            as_strings=False, print_per_layer_stat=False, verbose=False)\n",
    "    macs_encoder, _ = get_model_complexity_info(baseline_model.encoder, tuple(img_tensor.shape[1:]),\n",
    "                                                as_strings=False, print_per_layer_stat=False, verbose=False)\n",
    "    macs_decoder, _ = profile(baseline_model.decoder, inputs=(feature_maps, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:<30} {:<8}\".format(\"Baseline (dense) operations\", \"GFLOPs\"))\n",
    "print(\"{:<30} {:.3f}\".format(\"Encoder (flops-counter)\", macs_encoder / 10**9))\n",
    "print(\"{:<30} {:.3f}\".format(\"Decoder (thops) \", macs_decoder / 10**9))\n",
    "print(\"{:<30} {:.3f}\".format(\"All (flops-counter) \", macs_all / 10**9))\n",
    "print(\"{:<30} {:.3f}\".format(\"Decoder (flops-counter) \", (macs_all - macs_encoder) / 10**9))\n",
    "\n",
    "\n",
    "print(\"=\"*37)\n",
    "print(\"{:<30} {:<8}\".format(\"Wavelets version operations\", \"GFLOPs\"))\n",
    "print(\"{:<30} {:.3f}\".format(\"Dense operations \", total_ops_dense / 10**9))\n",
    "print(\"{:<30} {:.3f}\".format(\"Sparse operations \", sparse_outputs['total_ops'] / 10**9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "def depth_to_disp(depth):\n",
    "#     disp = np.log(depth)    \n",
    "    m = depth.min()\n",
    "    M = depth.max()\n",
    "    disp = (depth - m) / (M-m)\n",
    "    return 1-disp\n",
    "\n",
    "wave_range = 100\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 5, 1+5*i)\n",
    "    plt.imshow(sparse_outputs[('wavelet_mask', 2-i)][0,0])\n",
    "    plt.clim(0, 1)\n",
    "    \n",
    "    coeffs = [\"LH\", \"HL\", \"HH\"]\n",
    "    for j in range(3):\n",
    "        plt.subplot(3,5,1+(5*i)+j+1)\n",
    "        plt.imshow(sparse_outputs[(\"wavelets\", 2-i, coeffs[j])][0,0],\n",
    "                   vmin=-wave_range/(2**i), vmax = wave_range/(2**i),\n",
    "                   cmap='gray')        \n",
    "\n",
    "    plt.subplot(3, 5, 1+(5*i)+4)    \n",
    "    pred = sparse_outputs[('disp', 2-i)][0,0].numpy()/100\n",
    "    disp = depth_to_disp(pred)\n",
    "    plt.imshow(disp, cmap=\"inferno\", vmin = np.percentile(disp, 1), vmax = np.percentile(disp, 99))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
